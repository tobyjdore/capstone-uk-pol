{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UK Political Speech NLP project\n",
    "General Assembly DSI7 Capstone Project\n",
    "Toby Dore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The primary aim of this project is to build a model that takes the text of a speech by an MP and predicts their political party. I am also looking at the vocabulary used by MPs of different parties and some topic analysis.\n",
    "\n",
    "#### Data:\n",
    "\n",
    "The data was scraped from the <a href='http://www.ukpol.co.uk'>UK Political Speech</a> website. From this I got a dataset of around 3,000 speeches along with the speaker's name, the date of the speech, and a brief summary.\n",
    "\n",
    "The website didn't list the speaker's party in a reliable format so I used the Wikipedia API to determine this, which involved discarding a few hundred speeches where either the speaker's party couldn't be determined or the speaker wasn't an MP.\n",
    "\n",
    "I tokenised the speeches and limited the tokens to just those where the stem could be found in the 'words' corpus from NLTK. For training and testing I reduced the dataset to just the two main parties due to severe imbalance in the minority parties.\n",
    "\n",
    "#### Predictive modelling:\n",
    "\n",
    "I compared the following classification models:\n",
    "- Logistic Regression\n",
    "- Decision Tree (with Ada Boost)\n",
    "- Random Forest\n",
    "- Multinomial Naive Bayes\n",
    "- Bernoulli Naive Bayes\n",
    "- Support Vector Machines\n",
    "- Multi-layer Perceptron\n",
    "- doc2vec\n",
    "- keras\n",
    "\n",
    "I used CountVectorizer with all of the models (apart from doc2vec). I also tried a Tf-idf transformer with most of the models. I gridsearched the Logistic Regression, Naive Bayes, and SVM models, and manually tuned the other models where I could. I tried using a number of different ngrams for Logistic Regression and Naive Bayes.<p>\n",
    "I used the stopwords from the NLTK corpus. As I wanted the model to predict based on just the style of speaking rather than indicators like party names I looked at the strongest coefficients from the initial modelling and added the following:<p>\n",
    "    'conservative'<br>'conservatives'<br>'tory'<br>'tories'<br>'labour'<br>'jeremy'<br>'corbyn'<br>'george'<br>'may'<br>'pdf'\n",
    "\n",
    "#### Evaluation:\n",
    "\n",
    "As this was a classification problem where I wanted accurate results for both the majority and the minority classes I ranked my models based on the F1 scores rather than just accuracy. There was a class imbalance of around 70/30 between Conservative and Labour speeches, and while I felt that I could get away without under/over sampling I decided to rank the models by the macro F1 average rather than the weight average so ensure that the final model wasn't just good at predicting the majority class.\n",
    "\n",
    "#### Modelling results:\n",
    "\n",
    "- The sklearn Multi-Layer Perceptron performed the best, with a test accuracy of 0.88 (baseline was 0.72), an F1 score for the Conservative speeches of 0.92, and an F1 for the Labour speeches of 0.77.<br>\n",
    "- The second best model was the Logistic Regression with 1 ngram. I pulled out the coefficient words and displayed them using wordclouds based on their magnitude.<br>\n",
    "- Increasing the ngrams had mixed results, but helped noticeable with the Multinomial Naive Bayes model where using ngrams and range 4-6 was optimal.<br>\n",
    "- Adding a Tf-idf transformer reduced the accuracy and F1 average scores in all cases. I believe this is because it added importance to words that indicated the speech was about a specific subject (e.g. the NHS), but because both parties made speeches about the same subjects this didn't help to differentiate them.<br>\n",
    "- The Doc2vec model outperformed a number of other untuned models, but I didn't have enough experience with it to optimise it.\n",
    "\n",
    "#### Model deployment:\n",
    "\n",
    "I used flask to deploy a working version of the MLP model to <a href='http://tobyjdore.pythonanywhere.com'>python anywhere</a>.\n",
    "\n",
    "#### Additional analysis 1: Vocabulary\n",
    "\n",
    "I compared the number of distinct word stems used by various speakers in a randomised fixed length sample of their speeches. The samples I took indicated that Conservative speakers used more distinct words than Labour speakers, but running a Bayesian comparison with Pymc3 showed that the difference fell within the 95% credible interval.\n",
    "\n",
    "#### Additional analysis 2: Topic analysis\n",
    "\n",
    "I used LdaModel from gensim to generate 6 topics in the speeches, which I classified as:\n",
    "- Global\n",
    "- Business\n",
    "- UK Society\n",
    "- Crime\n",
    "- Education\n",
    "- Health\n",
    "\n",
    "The Conservative speeches were mostly on Global or Business topics with UK Society being the third biggest group, while Labour speeches were mostly in the UK Society topic, with Global and then Business topics coming second and third.<br>\n",
    "Crime and Education was about the same for both parties, but Labour seemed to make significantly more speeches about the NHS.<br>\n",
    "When restricted to just Maiden speeches, UK Society speeches were most common and Global speeches second most common for both parties.\n",
    "\n",
    "#### Progress blog:\n",
    "\n",
    "I've written blog posts as I've gone through the stages of this project. I've aimed to make it both interesting to people with some data science knowledge and accessible to people without any:\n",
    "#### <a href='https://mydsblog.home.blog'>mydsblog</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm_notebook\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import threading\n",
    "import re\n",
    "\n",
    "import wikipedia\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "My scraping functions. The speeches were organised by speaker surname,\n",
    "but the page for 'C' surnames was formatted differently so needed special handling.\n",
    "There were no speeches for 'X' so I used ascii_lowercase from the string module, removed\n",
    "the 'x', and then used this as my thread list.\n",
    "This returned the text of the link to each speech (which contained the name of the speaker,\n",
    "the year, and a description) and the body of the speech itself:\n",
    "'''\n",
    "\n",
    "def get_speeches(url1, url2, letter, return_dict):\n",
    "    if letter == 'c':\n",
    "        r = requests.get(url2.format(letter))\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        content_list = soup.find('div', attrs={'class':'site-content'})\n",
    "    else:\n",
    "        r = requests.get(url1.format(letter))\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        content_list = soup.find('div', attrs={'class':'entry-content'})\n",
    "    speeches = []\n",
    "    for result in tqdm_notebook(content_list.findAll('a', href=True)):\n",
    "        if result.text != 'Speeches Index':\n",
    "            try:\n",
    "                speech_url = result.get('href')\n",
    "                speech_r = requests.get(speech_url)\n",
    "                speech_soup = BeautifulSoup(speech_r.text, 'html.parser')\n",
    "                speech_text = speech_soup.find('div', attrs={'class':'entry-content'}).text\n",
    "                speeches.append([result.text,speech_text])\n",
    "            except:\n",
    "                try:\n",
    "                    speeches.append([result.text,'unable to scrape'])\n",
    "                except:\n",
    "                    pass\n",
    "    return_dict[letter]=speeches\n",
    "\n",
    "    \n",
    "def request_thread(url1, url2, letters):\n",
    "    manager = mp.Manager()\n",
    "    return_dict = manager.dict()\n",
    "    threads = []\n",
    "    for letter in tqdm_notebook(letters):\n",
    "        thread = threading.Thread(name=letter, \n",
    "                                  target=get_speeches, \n",
    "                                  args=(url1, url2, letter, return_dict))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    return return_dict\n",
    "\n",
    "from string import ascii_lowercase\n",
    "\n",
    "url1 = \"http://www.ukpol.co.uk/speeches/speeches-{}/\"\n",
    "url2 = \"http://www.ukpol.co.uk/speeches/{}/\"\n",
    "\n",
    "my_letters = ascii_lowercase\n",
    "for letter in my_letters:\n",
    "    if letter == 'x':\n",
    "        my_letters = my_letters.replace(letter,'')\n",
    "        \n",
    "speeches_dict = request_thread(url1, url2, my_letters)\n",
    "speeches1 = pd.DataFrame([x for letter in speeches_dict.values() for x in letter])\n",
    "speeches1.columns = ['title','speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The speeches had headers containing the date of the speech and a description.\n",
    "I extracted these headers:\n",
    "'''\n",
    "\n",
    "indicators = ['Below is the text',\n",
    "              'Below is the speech',\n",
    "              'The below speech',\n",
    "              'The speech below',\n",
    "              'Below is the Hansard record',\n",
    "              'Below is a part of the speech',\n",
    "              'This is the text',\n",
    "              'This speech was made',\n",
    "              'Speech made',\n",
    "              'Speech given',\n",
    "              'Below is the statement',\n",
    "              'Below is the transcript',\n",
    "              'Below is a transcript',\n",
    "              'Below is a text',\n",
    "              'Below is the Q&A',\n",
    "              'Below is the Passover message',\n",
    "              'Below is the Christmas message',\n",
    "              'Below is the 2013 Christmas message',\n",
    "              'This speech was given',\n",
    "              'Transcript of speech',\n",
    "              'Transcript of press conference']\n",
    "\n",
    "def find_header(text):\n",
    "    text_split = text.split('\\n')\n",
    "    for indicator in indicators:\n",
    "        for i, subtext in enumerate(text_split):\n",
    "            if indicator in subtext:\n",
    "                return i\n",
    "    return -1\n",
    "\n",
    "def get_header(text):\n",
    "    header_index = find_header(text)\n",
    "    if  header_index > -1:\n",
    "        return text.split('\\n')[header_index]\n",
    "    else:\n",
    "        return 'No header'\n",
    "\n",
    "def get_text(text):\n",
    "    header_index = find_header(text)\n",
    "#     I'm going to return the speech still separated by \\n so that I can split out further features later.\n",
    "    return '\\n'.join(text.split('\\n')[header_index+1:])\n",
    "\n",
    "uk_pol_clean = speeches1.copy()\n",
    "uk_pol_clean.columns = ['title','raw_speech']\n",
    "uk_pol_clean['description'] = uk_pol_clean.raw_speech.map(lambda x: get_header(x))\n",
    "uk_pol_clean['text'] = uk_pol_clean.raw_speech.map(lambda x: get_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "I then extracted the speaker name, year, and subject from the titles:\n",
    "'''\n",
    "def get_speaker(text):\n",
    "    longname = text.split('–')[0]\n",
    "    if '20' in longname or '19' in longname or '18' in longname:\n",
    "        name = ('{} {}').format(longname.split(' ')[1].strip().replace('-',''),\n",
    "                                longname.split(' ')[0].strip().replace(',',''))\n",
    "    elif ',' in longname:\n",
    "        name = ('{} {}').format(longname.split(',')[1].strip(),\n",
    "                                longname.split(',')[0].strip())\n",
    "    else:\n",
    "        name = longname.strip()\n",
    "    return name\n",
    "\n",
    "def get_year(text):\n",
    "    result = re.findall(year_ident, text)\n",
    "    if result:\n",
    "        year = int(result[0])\n",
    "    else:\n",
    "        year = 0\n",
    "    return year\n",
    "\n",
    "subject_prefixes = ['Speech in Tribute to ','Tribute to ','Speech on ','Speech to ','Speech about ',\n",
    "                    'Speech following ','Speech after ','Speech After ',\n",
    "                    'Speech against ','Statement on ','Statement following ','Statement after ']\n",
    "\n",
    "def get_subject(title, year):\n",
    "    if year > 0:\n",
    "        subject = title.split(str(year))[1].strip().replace(' the ',' ')\n",
    "    else:\n",
    "        subject = title.strip()\n",
    "    if 'Maiden Speech' not in subject:\n",
    "        for prefix in subject_prefixes:\n",
    "            subject = subject.replace(prefix,'')\n",
    "    else:\n",
    "        subject = 'Maiden Speech'\n",
    "    return subject\n",
    "\n",
    "uk_pol_clean['speaker'] = uk_pol_clean.title.map(lambda x: get_speaker(x))\n",
    "uk_pol_clean['year'] = uk_pol_clean.title.map(lambda x: get_year(x))\n",
    "uk_pol_clean['year'] = uk_pol_clean.year.astype(int)\n",
    "uk_pol_clean['subject'] = uk_pol_clean.apply(lambda x: get_subject(x['title'],x['year']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "I extracted the full date from the previously extracted header:\n",
    "'''\n",
    "full_date = re.compile(r'[0-9]{1,2}[stndrdth]{0,2} [A-Z][a-z]+ [0-9]{4}')\n",
    "\n",
    "def find_full_date(text):\n",
    "    dates = re.findall(full_date, text)\n",
    "    if dates:\n",
    "        date = dates[0]\n",
    "    else:\n",
    "        date = np.nan\n",
    "    return date\n",
    "\n",
    "uk_pol_clean['date'] = uk_pol_clean.description.map(lambda x: find_full_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "I used the Wikipedia api to get the categories associated with each speaker's page.\n",
    "I discarded any speaker who returned more or less than one identifiable party.\n",
    "'''\n",
    "party_dict = {'Conservative Party':'Conservative',\n",
    "              'Labour Party':'Labour',\n",
    "              'Labour Co-operative':'Labour',\n",
    "              'Trades Union':'Labour',\n",
    "              'Liberal Democrat':'Lib Dem',\n",
    "              'Liberal Party':'Lib Dem',\n",
    "              'Green Party':'Greens',\n",
    "              'Scottish National Party':'SNP',\n",
    "              'Plaid Cymru':'Plaid Cymru',\n",
    "              'Sinn Féin':'Sinn Féin',\n",
    "              'Ulster Unionist Party':'UUP',\n",
    "              'Democratic Unionist Party':'DUP',\n",
    "              'UK Independence Party':'UKIP'}\n",
    "\n",
    "def get_party(name):\n",
    "    try:\n",
    "        wiki_cats = wikipedia.WikipediaPage(title=name).categories\n",
    "    except:\n",
    "        try:\n",
    "            longname = name +' (politician)'\n",
    "            wiki_cats = wikipedia.WikipediaPage(title=longname).categories\n",
    "        except:\n",
    "            try:\n",
    "                longname = name +' (British politician)'\n",
    "                wiki_cats = wikipedia.WikipediaPage(title=longname).categories\n",
    "            except:\n",
    "                try:\n",
    "                    longname = name +' (Labour politician)'\n",
    "                    wiki_cats = wikipedia.WikipediaPage(title=longname).categories\n",
    "                except:\n",
    "                    try:\n",
    "                        longname = name +' (Northern Ireland politician)'\n",
    "                        wiki_cats = wikipedia.WikipediaPage(title=longname).categories\n",
    "                    except:\n",
    "                        wiki_cats = []\n",
    "    wiki_cats_joined = ', '.join(wiki_cats)\n",
    "#     looking back on the following bit of code I can see how shoddy it is, I must have\n",
    "#     written it in a rush. it works though as it returns the dictionary items in the\n",
    "#     order that they were created.\n",
    "    party_count=0\n",
    "    party_name = 'No name'\n",
    "    for ref, party in party_dict.items():\n",
    "        if ref in wiki_cats_joined:\n",
    "            if party != party_name:\n",
    "                party_count+=1\n",
    "            party_name = party\n",
    "    return name, party_name, party_count\n",
    "\n",
    "def get_parties(index_group, indexes, return_dict):\n",
    "    results = []\n",
    "    for ind in tqdm_notebook(indexes):\n",
    "        name = speakers.iloc[ind,0]\n",
    "        speech_count = speakers.iloc[ind,1]\n",
    "        name, party_name, party_count = get_party(name)\n",
    "        results.append([name, speech_count, party_name, party_count])\n",
    "    return_dict[index_group]=results\n",
    "    \n",
    "def request_thread(index_groups):\n",
    "    manager = mp.Manager()\n",
    "    return_dict = manager.dict()\n",
    "    threads = []\n",
    "    for index_group, indexes in tqdm_notebook(index_groups.items()):\n",
    "        thread = threading.Thread(name=index_group, \n",
    "                                  target=get_parties, \n",
    "                                  args=(index_group, indexes, return_dict))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    return return_dict\n",
    "\n",
    "# get a list of speakers that I'd extracted from the scraped speech data\n",
    "speakers = pd.read_csv('speakers.csv')\n",
    "\n",
    "# split the speaker names up into chunks of 50 so I can thread the Wikipedia requests\n",
    "name_index_groups = range(speakers.shape[0],0,-50)\n",
    "indexes = {group:[i for i in range(0,group) if group-i<51] for group in name_index_groups}\n",
    "\n",
    "parties_dict = request_thread(indexes)\n",
    "speaker_parties = pd.DataFrame([x for group in parties_dict.values() for x in group],columns=['name','speech_count','party','party_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "I wrote a function to tokenise the speeches and compare against 'words' list from NLTK:\n",
    "'''\n",
    "stop = stopwords.words('english')\n",
    "# add additional stopwords based on the strongest predictors from the weak model:\n",
    "stop = stop + ['conservative',\n",
    "               'conservatives',\n",
    "               'tory',\n",
    "               'tories',\n",
    "               'labour',\n",
    "               'jeremy',\n",
    "               'corbyn',\n",
    "               'george',\n",
    "               'may',\n",
    "               'pdf',\n",
    "               '.']\n",
    "\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "words_join = ' '.join(words)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def get_tokens(text):\n",
    "    tokens_text = []\n",
    "    for i in word_tokenize(text.lower()):\n",
    "        try:\n",
    "            if i not in stop and re.findall((stemmer.stem(i) + r'[a-z]*'), words_join):\n",
    "                tokens_text.append(i)\n",
    "        except:\n",
    "            pass\n",
    "    return tokens_text\n",
    "\n",
    "uk_pol_df['tokenised'] = uk_pol_df.apply(lambda x: get_tokens(x.name, x.text), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "I used a pipeline to quickly train the sklearn models and return scores.\n",
    "I could have written this into a function but in the end I just copied and pasted\n",
    "the code for different models:\n",
    "'''\n",
    "train_df, test_df = train_test_split(uk_pol_tokens, \n",
    "                                     stratify=uk_pol_tokens['party'], \n",
    "                                     test_size=0.3, random_state=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(lowercase=True, strip_accents='unicode', stop_words=stop)),\n",
    "    ('logreg', LogisticRegression(solver='lbfgs'))\n",
    "]) \n",
    "\n",
    "pipeline.fit(train_df.tokenised, train_df.party)\n",
    "\n",
    "print(pipeline.score(train_df.tokenised, train_df.party))\n",
    "print(cross_val_score(pipeline, train_df.tokenised, train_df.party, cv=5).mean())\n",
    "print(pipeline.score(test_df.tokenised, test_df.party))\n",
    "\n",
    "predictions = pipeline.predict(test_df.tokenised)\n",
    "\n",
    "print()\n",
    "print(classification_report(test_df.party, predictions))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(test_df.party, predictions,\n",
    "                              labels=test_df.party.unique()),\n",
    "             columns=test_df.party.unique(),\n",
    "             index=test_df.party.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "For gridsearching I dropped the pipeline and created pre-vectorized train and test sets:\n",
    "'''\n",
    "X_train = train_df.tokenised\n",
    "X_test = test_df.tokenised\n",
    "y_train = train_df.party\n",
    "y_test = test_df.party\n",
    "\n",
    "# basic count vectorizer\n",
    "cvec = CountVectorizer(lowercase=True, stop_words=stop, strip_accents='unicode')\n",
    "X_train_v = cvec.fit_transform(X_train)\n",
    "X_test_v = cvec.transform(X_test)\n",
    "\n",
    "# vectorizer with 4-6 ngrams\n",
    "cvec_ngrams = CountVectorizer(lowercase=True, stop_words=stop, ngram_range=(4,6), strip_accents='unicode')\n",
    "X_train_n = cvec.fit_transform(X_train)\n",
    "X_test_n = cvec.transform(X_test)\n",
    "\n",
    "# binary vectorizer for the Bernoulli Naive Bayes model\n",
    "bvec = CountVectorizer(lowercase=True, stop_words=stop, binary=True)\n",
    "X_train_b = bvec.fit_transform(X_train)\n",
    "X_test_b = bvec.transform(X_test)\n",
    "\n",
    "# Tf-idf vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=stop)\n",
    "X_train_t = tfidf.fit_transform(X_train)\n",
    "X_test_t = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Example of gridsearched model:\n",
    "'''\n",
    "clf = MultinomialNB()\n",
    "\n",
    "gs_params = {'alpha':np.linspace(0.1,3,20)}\n",
    "\n",
    "gs = GridSearchCV(clf,\n",
    "                  gs_params,\n",
    "                  cv=5,\n",
    "                  n_jobs=-1,\n",
    "                  verbose=1)\n",
    "\n",
    "gs.fit(X_train_v, y_train)\n",
    "\n",
    "print('Best score: {}'.format(gs.best_score_))\n",
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print()\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "clf.fit(X_train_v, y_train)\n",
    "\n",
    "print(clf.score(X_train_v, y_train))\n",
    "print()\n",
    "scores = cross_val_score(clf, X_train_v, y_train, cv=5)\n",
    "print(scores.mean())\n",
    "print()\n",
    "print(clf.score(X_test_v, y_test))\n",
    "print()\n",
    "predictions = clf.predict(X_test_v)\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, predictions),\n",
    "                   index=['con_actual','lab_actual'],\n",
    "                   columns=['con_pred','lab_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Final best model - MLP Classifier.\n",
    "I tuned it manually as I wasn't sure how gridsearch would react to it, and it's slow to fit:\n",
    "'''\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(lowercase=True, strip_accents='unicode', stop_words=stop)),\n",
    "    ('clf', MLPClassifier(activation='relu', \n",
    "                                alpha=1e-6, \n",
    "                                hidden_layer_sizes=(100,100), \n",
    "                                random_state=1))\n",
    "]) \n",
    "\n",
    "pipeline.fit(train_df.tokenised, train_df.party)\n",
    "\n",
    "print(pipeline.score(train_df.tokenised, train_df.party))\n",
    "print(cross_val_score(pipeline, train_df.tokenised, train_df.party, cv=5).mean())\n",
    "print(pipeline.score(test_df.tokenised, test_df.party))\n",
    "\n",
    "predictions = pipeline.predict(test_df.tokenised)\n",
    "\n",
    "print()\n",
    "print(classification_report(test_df.party, predictions))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(test_df.party, predictions,\n",
    "                              labels=test_df.party.unique()),\n",
    "             columns=test_df.party.unique(),\n",
    "             index=test_df.party.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Modelling Results:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### I got the following F1 scores, ranked by macro F1 average:\n",
    "<img src='summary-images/model-results.png'>\n",
    "#### The Multi-Layer Perceptron had the best results and gave the following confusion matrix for the test set (columns are predicted, rows are actual):\n",
    "<img src='summary-images/confusion-matrix.png'>\n",
    "#### ROC and Precision-Recall curves:\n",
    "<img src='summary-images/roc-curve.png'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Wordclouds from the strongest coefficients from the Logistic Regression model (2nd best):\n",
    "#### Conservatives:\n",
    "<img src='summary-images/con-wordcloud.png'>\n",
    "#### Labour:\n",
    "<img src='summary-images/lab-wordcloud.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "I wrote a function to concatenate the tokenised speeches for each speaker\n",
    "and return a count of unique stems for a fixed sample size:\n",
    "'''\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def unique_words_sample(name, sample_size, df):\n",
    "    speaker_text = []\n",
    "    for i, row in df[df.speaker==name].iterrows():\n",
    "        speaker_text += row.tokenized\n",
    "        \n",
    "#   I realised that the graphs were looking a bit wobbly. shuffling the text smoothed them out.\n",
    "#   Also, re-running this gave slightly different results so I'm going to run it 5 times and take the mean.\n",
    "    samples = []\n",
    "    samples_unique = []\n",
    "    for sample in range(5):\n",
    "        \n",
    "        shuffle(speaker_text)\n",
    "        stemmed_text = [stemmer.stem(word) for word in speaker_text]\n",
    "        text_sample = stemmed_text[:sample_size]\n",
    "        samples.append(len(text_sample))\n",
    "        samples_unique.append(len(set(text_sample)))\n",
    "    \n",
    "#   need to check that we've actually got the required number of words after stemming\n",
    "    word_count = int(np.mean(samples))\n",
    "    unique_count = int(np.mean(samples_unique))\n",
    "    party = df[df.speaker==name].iloc[0].party\n",
    "    \n",
    "    return party, word_count, unique_count\n",
    "\n",
    "vocab = {}\n",
    "vocab['name'] = []\n",
    "vocab['party'] = []\n",
    "vocab['word_count'] = []\n",
    "vocab['unique_count'] = []\n",
    "\n",
    "for name in vocab_speakers:\n",
    "    party, word_count, unique_count = unique_words_sample(name, 15000, uk_pol_final)\n",
    "    vocab['name'].append(name)\n",
    "    vocab['party'].append(party)\n",
    "    vocab['word_count'].append(word_count)\n",
    "    vocab['unique_count'].append(unique_count)\n",
    "    \n",
    "vocab_df = pd.DataFrame(vocab)\n",
    "\n",
    "# sorting the results into bins and ranking them\n",
    "vocab_df['bin'] = pd.cut(vocab_df.unique_count,20)\n",
    "vocab_df['bin_mid'] = vocab_df.bin.map(lambda x: np.round(x.mid,-2))\n",
    "vocab_df['ranking'] = vocab_df.sort_values('unique_count').groupby('bin_mid').cumcount()\n",
    "vocab_df['st_rank'] = vocab_df.groupby('bin_mid').ranking.apply(lambda x: x-x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Plotting the results:\n",
    "'''\n",
    "color_dict = {'Conservative':'#0087DC',\n",
    "              'Labour':'#DC241f',\n",
    "              'Lib Dem':'#FAA61A'}\n",
    "\n",
    "color_list = vocab_df.party.map(lambda x: color_dict[x])\n",
    "\n",
    "rcParams['axes.titlepad']=20\n",
    "\n",
    "# note: I had to manually adjust the width and height to get pleasing separation between\n",
    "# the tiles on the graph, but it should be fairly straightforward to set them automatically\n",
    "# based on the number of tiles in the largest bin and the difference between the highest\n",
    "# and lowest unique word count.\n",
    "fig, ax = plt.subplots(figsize=(32,16))\n",
    "\n",
    "for i, row in vocab_df.iterrows():\n",
    "    marker_name = '\\n'.join(row['name'].split(' '))\n",
    "    ax.scatter(x=row.bin_mid, \n",
    "               y=row.st_rank, \n",
    "               color=color_dict[row.party], \n",
    "               s=7000, marker='s')\n",
    "    plt.annotate(marker_name, xy=(row.bin_mid, row.st_rank), \n",
    "                 horizontalalignment='center',\n",
    "                 verticalalignment='center',fontsize='x-large',color='white',fontweight='bold')\n",
    "\n",
    "bins = vocab_df.bin_mid.sort_values().unique().astype(int)\n",
    "bin_ticks = np.arange(bins.min(),bins.max()+1,200)\n",
    "\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Unique words in 15,000 word sample', fontsize=30)\n",
    "ax.set_xticks(bin_ticks)\n",
    "ax.set_xticklabels(bin_ticks, fontsize=20)\n",
    "ax.xaxis.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Graph of unique words for various speakers based on a 15,000 word sample:\n",
    "<img src='summary-images/vocab-tiles.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "I took unique counts for a sample size of 4,000 words from as many Labour and Conservative\n",
    "speakers as possible and compared them. I ended up with unique word counts for\n",
    "78 Conservative speakers and 30 Labour speakers. Means of the samples were around 1400,\n",
    "standard deviations around 150.\n",
    "'''\n",
    "conlab_mean = vocab_df2_top.unique_count.mean()\n",
    "conlab_std = vocab_df2_top.unique_count.std()\n",
    "\n",
    "std_prior_lower = 1.\n",
    "std_prior_upper = 1000.\n",
    "\n",
    "con_unique = vocab_df2_top[vocab_df2_top.party=='Conservative'].unique_count\n",
    "lab_unique = vocab_df2_top[vocab_df2_top.party=='Labour'].unique_count\n",
    "\n",
    "with pm.Model() as conlab_model:\n",
    "\n",
    "    con_mean = pm.Normal('con_mean', mu=conlab_mean, sd=conlab_std)\n",
    "    lab_mean = pm.Normal('lab_mean', mu=conlab_mean, sd=conlab_std)\n",
    "    \n",
    "    con_std = pm.Uniform('con_std', lower=std_prior_lower, upper=std_prior_upper)\n",
    "    lab_std = pm.Uniform('lab_std', lower=std_prior_lower, upper=std_prior_upper)\n",
    "    \n",
    "    con = pm.Normal('con', mu=con_mean, sd=con_std, observed=con_unique)\n",
    "    lab = pm.Normal('lab', mu=lab_mean, sd=lab_std, observed=lab_unique)\n",
    "    \n",
    "    diff_of_means = pm.Deterministic('mean_diff', con_mean - lab_mean)\n",
    "    \n",
    "with conlab_model:\n",
    "    \n",
    "    trace = pm.sample(5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Graph of mean_diff:\n",
    "<img src='summary-images/mean-diff.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Topic Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generated 6 topics:\n",
    "'''\n",
    "doc_clean = [text for text in uk_pol_tokens.tokenised]\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=6, id2word = dictionary, passes=50)\n",
    "\n",
    "topics = ldamodel.print_topics(num_topics=6, num_words=8)\n",
    "topic_ident = re.compile(r'[a-z]+')\n",
    "\n",
    "def get_topic(text):\n",
    "    '''function to return the cleaned topic words list for a text'''\n",
    "    bowvector = dictionary.doc2bow(text)\n",
    "    topic_no = sorted(ldamodel[bowvector], key=lambda tup: -1*tup[1])[0][0]\n",
    "    topic_list_dirty = ldamodel.print_topics(num_topics=6, num_words=8)[topic_no][1].split('+')\n",
    "    topic_list_clean = []\n",
    "    for topic in topic_list_dirty:\n",
    "        topic_list_clean.append(' '.join(re.findall(topic_ident,topic)))\n",
    "    return ' '.join(topic_list_clean)\n",
    "\n",
    "uk_pol_tokens['topic'] = uk_pol_tokens.tokenised.map(lambda x: get_topic(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Assigned topic titles based on the topic words:\n",
    "'''\n",
    "topic_dict = {'eu uk world would us europe people trade':'global',\n",
    "              'new uk government also world business year investment':'business',\n",
    "              'people government country work one need make want':'uk society',\n",
    "              'police crime people public women also work policing':'crime',\n",
    "              'schools education people children school young work want':'education',\n",
    "              'nhs health services care patients public service new':'health'}\n",
    "\n",
    "uk_pol_topics['topic_title'] = uk_pol_topics.topic.map(lambda x: topic_dict[x])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Topics by party:\n",
    "<img src='summary-images/speech-topics.png'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Maiden Speech topics by party:\n",
    "<img src='summary-images/m-speech-topics.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
