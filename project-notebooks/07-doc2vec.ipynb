{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import ast\n",
    "import nltk\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_pol_tokens = pd.read_csv('uk_pol_tokens.csv', converters={4:ast.literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>party</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>tokenised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mark Isherwood</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>Fuel Poverty</td>\n",
       "      <td>[chartered, institute, housing, states, reason...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          speaker         party        date       subject  \\\n",
       "0  Mark Isherwood  Conservative  2006-01-10  Fuel Poverty   \n",
       "\n",
       "                                           tokenised  \n",
       "0  [chartered, institute, housing, states, reason...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_pol_tokens.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(uk_pol_tokens, stratify=uk_pol_tokens['party'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = train_df.apply(lambda x: TaggedDocument(words=x.tokenised, tags=[x.party]), axis=1)\n",
    "test_tagged = test_df.apply(lambda x: TaggedDocument(words=x.tokenised, tags=[x.party]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a distributed bag of words model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1675/1675 [00:00<00:00, 878841.53it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1675/1675 [00:00<00:00, 635155.88it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1349492.74it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1548139.97it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 897134.36it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1360731.98it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1494142.75it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1604352.41it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1575921.76it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1315629.06it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 871969.62it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1334623.71it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1519675.36it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1360731.98it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 884039.16it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1301251.94it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1344328.21it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1193182.61it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1717716.19it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1322066.09it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1208577.19it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1598511.76it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1018182.49it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 882373.67it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1616534.56it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1296449.38it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1562254.66it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1709357.47it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 891895.29it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1554993.18it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1648781.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 37s, sys: 1.62 s, total: 2min 38s\n",
      "Wall time: 48.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=100000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.Series(y_test).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751044776119403\n",
      "0.6518105849582173\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Conservative       0.72      0.84      0.78       517\n",
      "      Labour       0.28      0.16      0.20       201\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       718\n",
      "   macro avg       0.50      0.50      0.49       718\n",
      "weighted avg       0.60      0.65      0.62       718\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conservative</th>\n",
       "      <th>Labour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Conservative</th>\n",
       "      <td>436</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labour</th>\n",
       "      <td>169</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Conservative  Labour\n",
       "Conservative           436      81\n",
       "Labour                 169      32"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(logreg.score(X_train, y_train))\n",
    "print(logreg.score(X_test, y_test))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred,\n",
    "                              labels=labels),\n",
    "             columns=labels,\n",
    "             index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are pretty poor. Try a distributed memory model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1675/1675 [00:00<00:00, 755832.08it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1675/1675 [00:00<00:00, 828278.61it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1230593.66it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1541008.82it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1169740.13it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 878182.40it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1461505.97it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1269049.71it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1686784.92it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1639164.54it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1266076.63it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1246090.67it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1673525.30it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1638782.18it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1702316.26it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1460594.43it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1606186.37it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1215477.37it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1618023.77it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 868734.91it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1757683.06it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1294776.85it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 916802.71it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1542362.06it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1015680.09it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 995248.51it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1609129.45it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1370821.31it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1711022.70it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1353131.59it/s]\n",
      "100%|██████████| 1675/1675 [00:00<00:00, 1198883.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 39s, sys: 2.83 s, total: 4min 42s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8398328690807799\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Conservative       0.88      0.91      0.89       517\n",
      "      Labour       0.74      0.67      0.70       201\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       718\n",
      "   macro avg       0.81      0.79      0.80       718\n",
      "weighted avg       0.84      0.84      0.84       718\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conservative</th>\n",
       "      <th>Labour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Conservative</th>\n",
       "      <td>469</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labour</th>\n",
       "      <td>67</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Conservative  Labour\n",
       "Conservative           469      48\n",
       "Labour                  67     134"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
    "logreg = LogisticRegression(C=100000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(logreg.score(X_train, y_train))\n",
    "print(logreg.score(X_test, y_test))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred,\n",
    "                              labels=labels),\n",
    "             columns=labels,\n",
    "             index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are much better, although not better than the count vectorised logreg model. Try concatenating the two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.841225626740947\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Conservative       0.89      0.89      0.89       517\n",
      "      Labour       0.71      0.72      0.72       201\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       718\n",
      "   macro avg       0.80      0.80      0.80       718\n",
      "weighted avg       0.84      0.84      0.84       718\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conservative</th>\n",
       "      <th>Labour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Conservative</th>\n",
       "      <td>459</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labour</th>\n",
       "      <td>56</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Conservative  Labour\n",
       "Conservative           459      58\n",
       "Labour                  56     145"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(new_model, train_tagged)\n",
    "y_test, X_test = vec_for_learning(new_model, test_tagged)\n",
    "logreg = LogisticRegression(C=100000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(logreg.score(X_train, y_train))\n",
    "print(logreg.score(X_test, y_test))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred,\n",
    "                              labels=labels),\n",
    "             columns=labels,\n",
    "             index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using doc2vec hasn't given us any stronger results than just using a logistic regression with individual words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
